{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49509b9d-5cd9-4be6-8490-8ae68f7fd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.pardir))\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from voltaml.compile import VoltaGPUCompiler\n",
    "from voltaml.inference import gpu_performance\n",
    "import torchvision\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e4ce3e-65a1-4f79-982a-218bf9804c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/voltaML-1/demo\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da7bcd2-26a8-4931-87f2-192879359a45",
   "metadata": {},
   "source": [
    "### Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b0eddd-cc01-4ff5-a15f-b68e55cd2efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "# model = smp.DeepLabV3Plus(\n",
    "#             encoder_name=\"resnet50\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "#             encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "#             in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "#             classes=1,                      # model output channels (number of classes in your dataset)\n",
    "#         )\n",
    "\n",
    "model=torch.hub.load('pytorch/vision:v0.6.0', 'fcn_resnet101', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0d66c-6c4d-40cc-9665-2cc9b13a81b6",
   "metadata": {},
   "source": [
    "## Set parameters for FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e058bee-87fa-4042-8fd7-042e91180695",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,224,224)\n",
    "precision = 'fp16'\n",
    "compiled_model_dir = 'fcn_101.engine' ## Set Model dir\n",
    "throughput_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d1281-ad73-4469-ab4a-80342e2a6b18",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa38b10-4a0a-48c6-863f-5c80cae6163b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "INFO:EngineBuilder:Network Description\n",
      "Network Description\n",
      "Network Description\n",
      "INFO:EngineBuilder:Input 'onnx::Conv_0' with shape (1, 3, 224, 224) and dtype DataType.FLOAT\n",
      "Input 'onnx::Conv_0' with shape (1, 3, 224, 224) and dtype DataType.FLOAT\n",
      "Input 'onnx::Conv_0' with shape (1, 3, 224, 224) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output '1003' with shape (1, 21, 224, 224) and dtype DataType.FLOAT\n",
      "Output '1003' with shape (1, 21, 224, 224) and dtype DataType.FLOAT\n",
      "Output '1003' with shape (1, 21, 224, 224) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output '1022' with shape (1, 21, 224, 224) and dtype DataType.FLOAT\n",
      "Output '1022' with shape (1, 21, 224, 224) and dtype DataType.FLOAT\n",
      "Output '1022' with shape (1, 21, 224, 224) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Building fp16 Engine in /workspace/voltaML-1/demo/fcn_101.engine\n",
      "Building fp16 Engine in /workspace/voltaML-1/demo/fcn_101.engine\n",
      "Building fp16 Engine in /workspace/voltaML-1/demo/fcn_101.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/23/2022-13:05:27] [TRT] [I] [MemUsageChange] Init CUDA: CPU +313, GPU +0, now: CPU 1463, GPU 2545 (MiB)\n",
      "[08/23/2022-13:05:27] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 1463 MiB, GPU 2545 MiB\n",
      "[08/23/2022-13:05:28] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 1598 MiB, GPU 2579 MiB\n",
      "[08/23/2022-13:05:28] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[08/23/2022-13:05:28] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +513, GPU +224, now: CPU 2319, GPU 2803 (MiB)\n",
      "[08/23/2022-13:05:29] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +116, GPU +52, now: CPU 2435, GPU 2855 (MiB)\n",
      "[08/23/2022-13:05:29] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[08/23/2022-13:05:48] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[08/23/2022-13:06:05] [TRT] [I] Detected 1 inputs and 2 output network tensors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Serializing engine to file: /workspace/voltaML-1/demo/fcn_101.engine\n",
      "Serializing engine to file: /workspace/voltaML-1/demo/fcn_101.engine\n",
      "Serializing engine to file: /workspace/voltaML-1/demo/fcn_101.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/23/2022-13:06:05] [TRT] [I] Total Host Persistent Memory: 281376\n",
      "[08/23/2022-13:06:05] [TRT] [I] Total Device Persistent Memory: 108837888\n",
      "[08/23/2022-13:06:05] [TRT] [I] Total Scratch Memory: 0\n",
      "[08/23/2022-13:06:05] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 122 MiB, GPU 4415 MiB\n",
      "[08/23/2022-13:06:05] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 6.23747ms to assign 5 blocks to 113 nodes requiring 8467456 bytes.\n",
      "[08/23/2022-13:06:05] [TRT] [I] Total Activation Memory: 8467456\n",
      "[08/23/2022-13:06:05] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 3053, GPU 3187 (MiB)\n",
      "[08/23/2022-13:06:05] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 3053, GPU 3195 (MiB)\n",
      "[08/23/2022-13:06:05] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +103, GPU +104, now: CPU 103, GPU 104 (MiB)\n"
     ]
    }
   ],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision\n",
    "    # simplify=True\n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced82660-fd04-44ca-9a2d-878dd41f2ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating latency...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:14<00:00, 69.27it/s]\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "cuMemcpyHtoD failed: invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgpu_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiled_model_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthroughput_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_yolo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/voltaML-1/voltaml/inference.py:135\u001b[0m, in \u001b[0;36mgpu_performance\u001b[0;34m(compiled_model, model, input_shape, throughput_batch_size, is_yolo)\u001b[0m\n\u001b[1;32m    133\u001b[0m gpu_inference_model \u001b[38;5;241m=\u001b[39m TensorRTInfer(compiled_model)\n\u001b[1;32m    134\u001b[0m torch_latency \u001b[38;5;241m=\u001b[39m measure_gpu_inference_latency(model, input_size\u001b[38;5;241m=\u001b[39minput_shape, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m voltaml_gpu_latency \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_gpu_inference_latency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu_inference_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoltaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m torch_throughput \u001b[38;5;241m=\u001b[39m measure_gpu_inference_throughput(model, input_size\u001b[38;5;241m=\u001b[39minput_shape_for_throughput, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m voltaml_gpu_throughput \u001b[38;5;241m=\u001b[39m measure_gpu_inference_throughput(gpu_inference_model, input_size\u001b[38;5;241m=\u001b[39minput_shape_for_throughput, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoltaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/voltaML-1/voltaml/inference.py:306\u001b[0m, in \u001b[0;36mmeasure_gpu_inference_latency\u001b[0;34m(model, input_size, num_samples, num_warmups, model_type, is_yolo)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# x = torch.rand(size=input_size)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m): \n\u001b[0;32m--> 306\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m times \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/workspace/voltaML-1/voltaml/trt_infer.py:94\u001b[0m, in \u001b[0;36mTensorRTInfer.infer\u001b[0;34m(self, batch, top)\u001b[0m\n\u001b[1;32m     91\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_spec())\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Process I/O and execute the network\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemcpy_htod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mexecute_v2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallocations)\n\u001b[1;32m     96\u001b[0m cuda\u001b[38;5;241m.\u001b[39mmemcpy_dtoh(output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallocation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mLogicError\u001b[0m: cuMemcpyHtoD failed: invalid argument"
     ]
    }
   ],
   "source": [
    "gpu_performance(compiled_model_dir, model, input_shape=input_shape, throughput_batch_size=1, is_yolo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d5329-5d7a-4d20-8968-561c7b2070df",
   "metadata": {},
   "source": [
    "### Set parameters for INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a81e3-d86d-4811-a6a7-461005c9085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,224,224)\n",
    "precision = 'int8'\n",
    "compiled_model_dir = '' ## Compiled model directory\n",
    "throughput_batch_size = 1\n",
    "calib_input = '' ## Calib input images path\n",
    "calib_cache = '' ## Cache name\n",
    "calib_num_images=25000\n",
    "calib_batch_size=8\n",
    "calib_preprocessor='V2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff20c5f-ae4f-4334-af42-e6d0dad41431",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ab406-0681-4a8a-a8fe-49ccb59b2831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision,\n",
    "    calib_input=calib_input,\n",
    "    calib_cache=calib_cache,\n",
    "    calib_num_images=calib_num_images,\n",
    "    calib_batch_size=calib_batch_size,\n",
    "    calib_preprocessor=calib_preprocessor\n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcebab1-840b-4f43-82cb-578b82b0cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_performance(compiled_model_dir, model, input_shape=input_shape, throughput_batch_size=throughput_batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
