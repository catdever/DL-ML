{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec83ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.pardir))\n",
    "sys.path.append(os.path.abspath(os.path.pardir)+'/voltaml')\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from voltaml.compile import VoltaGPUCompiler\n",
    "from voltaml.inference import gpu_performance\n",
    "import torchvision\n",
    "from voltaml.models.common import DetectMultiBackend\n",
    "from voltaml.yolov6.utils.checkpoint import load_checkpoint\n",
    "from voltaml.yolov6.layers.common import DetectBackend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('../voltaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256f752f-d0c1-459c-b8c8-302e3caf72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71.5M/71.5M [00:07<00:00, 10.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download a pretrained model\n",
    "# import torch\n",
    "torch.hub.download_url_to_file('https://github.com/meituan/YOLOv6/releases/download/0.2.0/yolov6m.pt', 'yolov6m.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3892df",
   "metadata": {},
   "source": [
    "### Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacd4457-ed7d-4cb2-8454-62386907805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model_dir = 'yolov6m.pt'\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588b6de6-3fc2-4c3f-b90d-a452a9659ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:voltaml.yolov6.utils.events:Loading checkpoint from yolov6m.pt\n",
      "Loading checkpoint from yolov6m.pt\n",
      "Loading checkpoint from yolov6m.pt\n",
      "INFO:voltaml.yolov6.utils.events:\n",
      "Fusing model...\n",
      "\n",
      "Fusing model...\n",
      "\n",
      "Fusing model...\n"
     ]
    }
   ],
   "source": [
    "#Load PyTorch model\n",
    "model = load_checkpoint(torch_model_dir, map_location=device, inplace=True, fuse=True)  # load FP32 modeldo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91758d3d",
   "metadata": {},
   "source": [
    "## Set parameters for FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6b0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (16,3,640,640)\n",
    "precision = 'fp16'\n",
    "compiled_model_dir = 'yolov6m_16_640.engine' ## Compiled model directory\n",
    "is_yolo = True\n",
    "input_name = 'images'\n",
    "output_name = 'output'\n",
    "simplify = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4f365",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d078430b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Loading ONNX ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Network Description\n",
      "Network Description\n",
      "Network Description\n",
      "INFO:EngineBuilder:Input 'images' with shape (16, 3, 640, 640) and dtype DataType.FLOAT\n",
      "Input 'images' with shape (16, 3, 640, 640) and dtype DataType.FLOAT\n",
      "Input 'images' with shape (16, 3, 640, 640) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output 'output' with shape (16, 8400, 85) and dtype DataType.FLOAT\n",
      "Output 'output' with shape (16, 8400, 85) and dtype DataType.FLOAT\n",
      "Output 'output' with shape (16, 8400, 85) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Building fp16 Engine in /workspace/voltaML/voltaml/yolov6m_16_640.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/14/2022-13:13:35] [TRT] [I] [MemUsageChange] Init CUDA: CPU +314, GPU +0, now: CPU 2596, GPU 1817 (MiB)\n",
      "[10/14/2022-13:13:35] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 2596 MiB, GPU 1817 MiB\n",
      "[10/14/2022-13:13:35] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 2731 MiB, GPU 1851 MiB\n",
      "[10/14/2022-13:13:35] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building fp16 Engine in /workspace/voltaML/voltaml/yolov6m_16_640.engine\n",
      "Building fp16 Engine in /workspace/voltaML/voltaml/yolov6m_16_640.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/14/2022-13:13:37] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +513, GPU +226, now: CPU 3402, GPU 2085 (MiB)\n",
      "[10/14/2022-13:13:38] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +115, GPU +52, now: CPU 3517, GPU 2137 (MiB)\n",
      "[10/14/2022-13:13:38] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/14/2022-13:15:09] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[10/14/2022-13:16:29] [TRT] [I] Detected 1 inputs and 4 output network tensors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Serializing engine to file: /workspace/voltaML/voltaml/yolov6m_16_640.engine\n",
      "Serializing engine to file: /workspace/voltaML/voltaml/yolov6m_16_640.engine\n",
      "Serializing engine to file: /workspace/voltaML/voltaml/yolov6m_16_640.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/14/2022-13:16:29] [TRT] [I] Total Host Persistent Memory: 362656\n",
      "[10/14/2022-13:16:29] [TRT] [I] Total Device Persistent Memory: 74990592\n",
      "[10/14/2022-13:16:29] [TRT] [I] Total Scratch Memory: 24576000\n",
      "[10/14/2022-13:16:29] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 90 MiB, GPU 7693 MiB\n",
      "[10/14/2022-13:16:29] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 107.692ms to assign 13 blocks to 288 nodes requiring 596377605 bytes.\n",
      "[10/14/2022-13:16:29] [TRT] [I] Total Activation Memory: 596377605\n",
      "[10/14/2022-13:16:29] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 4125, GPU 2319 (MiB)\n",
      "[10/14/2022-13:16:29] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 4126, GPU 2327 (MiB)\n",
      "[10/14/2022-13:16:29] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +71, GPU +73, now: CPU 71, GPU 73 (MiB)\n"
     ]
    }
   ],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision,\n",
    "    input_name=input_name,\n",
    "    output_name=output_name,\n",
    "    simplify=simplify\n",
    "    \n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4fdbf14",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:yolov5:YOLOv5 ðŸš€ 2022-9-10 torch 1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11016MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-9-10 torch 1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11016MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-9-10 torch 1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11016MiB)\n",
      "\n",
      "INFO:yolov5:Loading yolov6m_16_640.engine for TensorRT inference...\n",
      "Loading yolov6m_16_640.engine for TensorRT inference...\n",
      "Loading yolov6m_16_640.engine for TensorRT inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/14/2022-13:16:30] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 3812, GPU 2964 (MiB)\n",
      "[10/14/2022-13:16:30] [TRT] [I] Loaded engine size: 75 MiB\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 3893, GPU 3048 (MiB)\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 3893, GPU 3058 (MiB)\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +73, now: CPU 1, GPU 785 (MiB)\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 3818, GPU 3170 (MiB)\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 3819, GPU 3178 (MiB)\n",
      "[10/14/2022-13:16:30] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +640, now: CPU 1, GPU 1425 (MiB)\n",
      "Total batches :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.66it/s]\n",
      "INFO:yolov5:Speed: 5.3ms pre-process, 32.4ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Speed: 5.3ms pre-process, 32.4ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Speed: 5.3ms pre-process, 32.4ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "INFO:yolov5:Speed: 5.3ms pre-process, 32.4ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Speed: 5.3ms pre-process, 32.4ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Speed: 5.3ms pre-process, 32.4ms inference, 25.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "INFO:yolov5:Speed: 0.0s pre-process, 0.0s inference, 0.0s NMS per image at shape (1, 3, 640, 640)\n",
      "Speed: 0.0s pre-process, 0.0s inference, 0.0s NMS per image at shape (1, 3, 640, 640)\n",
      "Speed: 0.0s pre-process, 0.0s inference, 0.0s NMS per image at shape (1, 3, 640, 640)\n",
      "INFO:yolov5:Results saved to \u001b[1m../voltaml/runs/detect/exp4\u001b[0m\n",
      "Results saved to \u001b[1m../voltaml/runs/detect/exp4\u001b[0m\n",
      "Results saved to \u001b[1m../voltaml/runs/detect/exp4\u001b[0m\n",
      "calculating latency...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [02:44<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency:\n",
      "--------------------------------------------------\n",
      "VoltaML GPU Inference Latency: 32.36 ms / sample\n",
      "PyTorch Inference Latency: 164.42 ms / sample\n",
      "\n",
      "\n",
      "FPS:\n",
      "--------------------------------------------------\n",
      "VoltaML GPU Inference Throughput: 30.91 fps\n",
      "PyTorch Inference Throughput: 6.08 fps\n"
     ]
    }
   ],
   "source": [
    "gpu_performance(compiled_model_dir, model, input_shape=input_shape, is_yolo=is_yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3116e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a5daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
