{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec83ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.pardir))\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from voltaml.compile import VoltaGPUCompiler\n",
    "from voltaml.inference import gpu_performance\n",
    "import torchvision\n",
    "from voltaml.models.common import DetectMultiBackend\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3892df",
   "metadata": {},
   "source": [
    "### Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9fd485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:yolov5:Fusing layers... \n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "INFO:yolov5:YOLOv5n summary: 270 layers, 1872157 parameters, 0 gradients\n",
      "YOLOv5n summary: 270 layers, 1872157 parameters, 0 gradients\n",
      "YOLOv5n summary: 270 layers, 1872157 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "torch_model_dir = 'voltaml/yolov5n.pt'\n",
    "model = DetectMultiBackend(torch_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91758d3d",
   "metadata": {},
   "source": [
    "## Set parameters for FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6b0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,1280,1280)\n",
    "precision = 'fp16'\n",
    "compiled_model_dir = 'yolov5n_1280_16.engine' ## Compiled model directory\n",
    "is_yolo = True\n",
    "input_name = 'images'\n",
    "output_name = 'output'\n",
    "simplify = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4f365",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d078430b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Loading ONNX ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Network Description\n",
      "Network Description\n",
      "Network Description\n",
      "INFO:EngineBuilder:Input 'images' with shape (1, 3, 1280, 1280) and dtype DataType.FLOAT\n",
      "Input 'images' with shape (1, 3, 1280, 1280) and dtype DataType.FLOAT\n",
      "Input 'images' with shape (1, 3, 1280, 1280) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output 'output' with shape (1, 100800, 85) and dtype DataType.FLOAT\n",
      "Output 'output' with shape (1, 100800, 85) and dtype DataType.FLOAT\n",
      "Output 'output' with shape (1, 100800, 85) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Building fp16 Engine in /workspace/voltav0.3/voltaML/demo/yolov5n_1280_16.engine\n",
      "Building fp16 Engine in /workspace/voltav0.3/voltaML/demo/yolov5n_1280_16.engine\n",
      "Building fp16 Engine in /workspace/voltav0.3/voltaML/demo/yolov5n_1280_16.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/20/2022-09:32:26] [TRT] [I] [MemUsageChange] Init CUDA: CPU +313, GPU +0, now: CPU 489, GPU 603 (MiB)\n",
      "[10/20/2022-09:32:26] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 489 MiB, GPU 603 MiB\n",
      "[10/20/2022-09:32:26] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 624 MiB, GPU 637 MiB\n",
      "[10/20/2022-09:32:26] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[10/20/2022-09:32:27] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +513, GPU +224, now: CPU 1171, GPU 865 (MiB)\n",
      "[10/20/2022-09:32:27] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +115, GPU +49, now: CPU 1286, GPU 914 (MiB)\n",
      "[10/20/2022-09:32:27] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/20/2022-09:35:49] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Serializing engine to file: /workspace/voltav0.3/voltaML/demo/yolov5n_1280_16.engine\n",
      "Serializing engine to file: /workspace/voltav0.3/voltaML/demo/yolov5n_1280_16.engine\n",
      "Serializing engine to file: /workspace/voltav0.3/voltaML/demo/yolov5n_1280_16.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/20/2022-09:35:58] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[10/20/2022-09:35:58] [TRT] [I] Total Host Persistent Memory: 134320\n",
      "[10/20/2022-09:35:58] [TRT] [I] Total Device Persistent Memory: 5668352\n",
      "[10/20/2022-09:35:58] [TRT] [I] Total Scratch Memory: 33955200\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 5 MiB, GPU 4298 MiB\n",
      "[10/20/2022-09:35:58] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 5.10551ms to assign 6 blocks to 77 nodes requiring 71161856 bytes.\n",
      "[10/20/2022-09:35:58] [TRT] [I] Total Activation Memory: 71161856\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1833, GPU 1153 (MiB)\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1833, GPU 1161 (MiB)\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +3, GPU +14, now: CPU 3, GPU 14 (MiB)\n"
     ]
    }
   ],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision,\n",
    "    input_name=input_name,\n",
    "    output_name=output_name,\n",
    "    simplify=simplify\n",
    "    \n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fdbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:yolov5:YOLOv5 ðŸš€ 2022-10-14 torch 1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11016MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-10-14 torch 1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11016MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-10-14 torch 1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11016MiB)\n",
      "\n",
      "INFO:yolov5:Loading yolov5n_1280_16.engine for TensorRT inference...\n",
      "Loading yolov5n_1280_16.engine for TensorRT inference...\n",
      "Loading yolov5n_1280_16.engine for TensorRT inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/20/2022-09:35:58] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1780, GPU 1224 (MiB)\n",
      "[10/20/2022-09:35:58] [TRT] [I] Loaded engine size: 24 MiB\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1819, GPU 1247 (MiB)\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 1819, GPU 1257 (MiB)\n",
      "[10/20/2022-09:35:58] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +14, now: CPU 0, GPU 101 (MiB)\n",
      "[10/20/2022-09:36:01] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 3536, GPU 2037 (MiB)\n",
      "[10/20/2022-09:36:01] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 3536, GPU 2045 (MiB)\n",
      "[10/20/2022-09:36:01] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +73, now: CPU 0, GPU 174 (MiB)\n",
      "Total batches :  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 75.37it/s]\n",
      "INFO:yolov5:Speed: 1.1ms pre-process, 2.5ms inference, 1.2ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "Speed: 1.1ms pre-process, 2.5ms inference, 1.2ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "Speed: 1.1ms pre-process, 2.5ms inference, 1.2ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "INFO:yolov5:Speed: 21.3ms pre-process, 49.1ms inference, 24.8ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "Speed: 21.3ms pre-process, 49.1ms inference, 24.8ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "Speed: 21.3ms pre-process, 49.1ms inference, 24.8ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "INFO:yolov5:Speed: 0.0s pre-process, 0.0s inference, 0.0s NMS per image at shape (1, 3, 1280, 1280)\n",
      "Speed: 0.0s pre-process, 0.0s inference, 0.0s NMS per image at shape (1, 3, 1280, 1280)\n",
      "Speed: 0.0s pre-process, 0.0s inference, 0.0s NMS per image at shape (1, 3, 1280, 1280)\n",
      "INFO:yolov5:Results saved to \u001b[1m../voltaml/utils/runs/detect/exp6\u001b[0m\n",
      "Results saved to \u001b[1m../voltaml/utils/runs/detect/exp6\u001b[0m\n",
      "Results saved to \u001b[1m../voltaml/utils/runs/detect/exp6\u001b[0m\n",
      "calculating latency...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:05<00:00, 169.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency:\n",
      "--------------------------------------------------\n",
      "VoltaML GPU Inference Latency: 2.45 ms / sample\n",
      "PyTorch Inference Latency: 5.90 ms / sample\n",
      "\n",
      "\n",
      "FPS:\n",
      "--------------------------------------------------\n",
      "VoltaML GPU Inference Throughput: 407.42 fps\n",
      "PyTorch Inference Throughput: 169.42 fps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_performance(compiled_model_dir,model, input_shape=input_shape, is_yolo=is_yolo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341b48d",
   "metadata": {},
   "source": [
    "### Set parameters for INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,224,224)\n",
    "precision = 'int8'\n",
    "compiled_model_dir = '' ## Compiled model directory\n",
    "throughput_batch_size = 1\n",
    "calib_input = '' ## Calib input images path\n",
    "calib_cache = '' ## Cache name\n",
    "calib_num_images=25000\n",
    "calib_batch_size=8\n",
    "calib_preprocessor='V2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966cfb9",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a64c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision,\n",
    "    calib_input=calib_input,\n",
    "    calib_cache=calib_cache,\n",
    "    calib_num_images=calib_num_images,\n",
    "    calib_batch_size=calib_batch_size,\n",
    "    calib_preprocessor=calib_preprocessor\n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_performance(compiled_model_dir, model, input_shape=input_shape, throughput_batch_size=throughput_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3116e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a5daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
