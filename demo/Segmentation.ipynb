{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec83ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.pardir))\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from voltaml.compile import VoltaGPUCompiler\n",
    "from voltaml.inference import gpu_performance\n",
    "import torchvision\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3892df",
   "metadata": {},
   "source": [
    "### Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ccc4c2-dd5c-4f8a-8eec-e60ce8392eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.DeepLabV3Plus(\n",
    "            encoder_name=\"resnet50\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=1,                      # model output channels (number of classes in your dataset)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91758d3d",
   "metadata": {},
   "source": [
    "## Set parameters for FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6b0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,224,224)\n",
    "precision = 'fp16'\n",
    "compiled_model_dir = 'deeplab.engine' ## Set Model dir\n",
    "throughput_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4f365",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d078430b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Loading ONNX ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Network Description\n",
      "Network Description\n",
      "Network Description\n",
      "INFO:EngineBuilder:Input 'onnx::Conv_0' with shape (1, 3, 224, 224) and dtype DataType.FLOAT\n",
      "Input 'onnx::Conv_0' with shape (1, 3, 224, 224) and dtype DataType.FLOAT\n",
      "Input 'onnx::Conv_0' with shape (1, 3, 224, 224) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output '614' with shape (1, 1, 224, 224) and dtype DataType.FLOAT\n",
      "Output '614' with shape (1, 1, 224, 224) and dtype DataType.FLOAT\n",
      "Output '614' with shape (1, 1, 224, 224) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Building fp16 Engine in /workspace/voltaML/demo/deeplab.engine\n",
      "Building fp16 Engine in /workspace/voltaML/demo/deeplab.engine\n",
      "Building fp16 Engine in /workspace/voltaML/demo/deeplab.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/29/2022-18:40:16] [TRT] [I] [MemUsageChange] Init CUDA: CPU +313, GPU +0, now: CPU 1116, GPU 781 (MiB)\n",
      "[08/29/2022-18:40:16] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 1116 MiB, GPU 781 MiB\n",
      "[08/29/2022-18:40:16] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 1251 MiB, GPU 815 MiB\n",
      "[08/29/2022-18:40:16] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "-------------------------------------\n",
      "Precision :  fp16\n",
      "[08/29/2022-18:40:17] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +513, GPU +224, now: CPU 1867, GPU 1039 (MiB)\n",
      "[08/29/2022-18:40:17] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +115, GPU +52, now: CPU 1982, GPU 1091 (MiB)\n",
      "[08/29/2022-18:40:17] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EngineBuilder:Serializing engine to file: /workspace/voltaML/demo/deeplab.engine\n",
      "Serializing engine to file: /workspace/voltaML/demo/deeplab.engine\n",
      "Serializing engine to file: /workspace/voltaML/demo/deeplab.engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/29/2022-18:40:41] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[08/29/2022-18:40:41] [TRT] [I] Total Host Persistent Memory: 144912\n",
      "[08/29/2022-18:40:41] [TRT] [I] Total Device Persistent Memory: 52366336\n",
      "[08/29/2022-18:40:41] [TRT] [I] Total Scratch Memory: 0\n",
      "[08/29/2022-18:40:41] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 51 MiB, GPU 2526 MiB\n",
      "[08/29/2022-18:40:41] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 3.81615ms to assign 7 blocks to 78 nodes requiring 7028736 bytes.\n",
      "[08/29/2022-18:40:41] [TRT] [I] Total Activation Memory: 7028736\n",
      "[08/29/2022-18:40:41] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2548, GPU 1371 (MiB)\n",
      "[08/29/2022-18:40:41] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2548, GPU 1379 (MiB)\n",
      "[08/29/2022-18:40:41] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +51, GPU +52, now: CPU 51, GPU 52 (MiB)\n"
     ]
    }
   ],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision,\n",
    "    simplify=True\n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fdbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating latency...: 100%|█████████████| 1000/1000 [00:06<00:00, 165.70it/s]\n",
      "calculating throughput: 100%|███████████████| 100/100 [00:00<00:00, 166.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency:\n",
      "--------------------------------------------------\n",
      "VoltaML GPU Inference Latency: 1.08 ms / sample\n",
      "PyTorch Inference Latency: 6.04 ms / sample\n",
      "\n",
      "\n",
      "Throughput:\n",
      "--------------------------------------------------\n",
      "VoltaML GPU Inference Throughput: 978.84 samples / s\n",
      "PyTorch Inference Throughput: 167.57 samples / s\n"
     ]
    }
   ],
   "source": [
    "gpu_performance(compiled_model_dir, model, input_shape=input_shape, throughput_batch_size=throughput_batch_size, is_yolo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341b48d",
   "metadata": {},
   "source": [
    "### Set parameters for INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,3,224,224)\n",
    "precision = 'int8'\n",
    "compiled_model_dir = '' ## Compiled model directory\n",
    "throughput_batch_size = 1\n",
    "calib_input = '' ## Calib input images path\n",
    "calib_cache = '' ## Cache name\n",
    "calib_num_images=25000\n",
    "calib_batch_size=8\n",
    "calib_preprocessor='V2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966cfb9",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a64c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compiler = VoltaGPUCompiler(\n",
    "    model=model,\n",
    "    output_dir=compiled_model_dir,\n",
    "    input_shape=input_shape,\n",
    "    precision=precision,\n",
    "    calib_input=calib_input,\n",
    "    calib_cache=calib_cache,\n",
    "    calib_num_images=calib_num_images,\n",
    "    calib_batch_size=calib_batch_size,\n",
    "    calib_preprocessor=calib_preprocessor\n",
    ")\n",
    "\n",
    "compiled_model = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_performance(compiled_model_dir, model, input_shape=input_shape, throughput_batch_size=throughput_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3116e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a5daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
